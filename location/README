Location Extraction from WikiCFP Data
Joey Wilson jwilso43@calpoly.edu

----- Dependecies -----
python3
nltk
beautiful soup
https://www.crummy.com/software/BeautifulSoup/
google nlp cloud account and associtated libs 
https://cloud.google.com/natural-language/docs/getting-started
Notes from the getting started guide:
- all configuration done on your cloud account as the guide specifes 
- google-cloud-sdk in your path
- google cloud private API key saved as a GOOGLE_APPLICATION_CREDENTIALS env variable

----- To Run -----
python3 where.py

this requires an output.json file generated by the scrape.py from the corpus folder to be present as input
this also requires the states.json and countries.json to be present
